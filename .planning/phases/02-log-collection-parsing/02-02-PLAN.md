---
phase: 02-log-collection-parsing
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/unifi_scanner/utils/__init__.py
  - src/unifi_scanner/utils/timestamps.py
  - src/unifi_scanner/models/log_entry.py
  - src/unifi_scanner/logs/__init__.py
  - src/unifi_scanner/logs/parser.py
  - tests/test_timestamps.py
  - tests/test_log_parser.py
autonomous: true

must_haves:
  truths:
    - "All timestamps are normalized to UTC with timezone awareness"
    - "Millisecond timestamps from UniFi API are correctly converted"
    - "Syslog format messages can be parsed into LogEntry objects"
    - "Malformed data fails gracefully with defaults instead of exceptions"
    - "MAC addresses are normalized to lowercase with colons"
  artifacts:
    - path: "src/unifi_scanner/utils/timestamps.py"
      provides: "UTC timestamp normalization"
      exports: ["normalize_timestamp"]
    - path: "src/unifi_scanner/logs/parser.py"
      provides: "Multi-format log parsing"
      exports: ["LogParser"]
    - path: "src/unifi_scanner/models/log_entry.py"
      provides: "Enhanced LogEntry with defensive parsing"
      contains: "field_validator"
  key_links:
    - from: "src/unifi_scanner/models/log_entry.py"
      to: "src/unifi_scanner/utils/timestamps.py"
      via: "normalize_timestamp in field_validator"
      pattern: "normalize_timestamp"
    - from: "src/unifi_scanner/logs/parser.py"
      to: "src/unifi_scanner/models/log_entry.py"
      via: "LogEntry.from_unifi_event and from_syslog"
      pattern: "LogEntry\\.from_"
---

<objective>
Create timestamp normalization utilities and multi-format log parser with defensive parsing.

Purpose: UniFi logs come from multiple sources (API JSON, SSH syslog) with inconsistent timestamp formats. This plan establishes robust parsing that normalizes all timestamps to UTC and handles malformed data gracefully, preventing crashes on unexpected input.

Output: A timestamps utility module, enhanced LogEntry model with Pydantic validators, and a LogParser class that handles JSON and syslog formats.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-log-collection-parsing/02-RESEARCH.md

# Key existing files
@src/unifi_scanner/models/log_entry.py
@src/unifi_scanner/models/enums.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create timestamp normalization utility</name>
  <files>
src/unifi_scanner/utils/__init__.py
src/unifi_scanner/utils/timestamps.py
  </files>
  <action>
1. Create `src/unifi_scanner/utils/` directory if it doesn't exist.

2. Create `src/unifi_scanner/utils/__init__.py`:
   - Export `normalize_timestamp` from timestamps module

3. Create `src/unifi_scanner/utils/timestamps.py` with:

```python
"""Timestamp normalization utilities for UniFi log data."""

from datetime import datetime, timezone
from typing import Any, Union

from dateutil import parser as dateutil_parser


def normalize_timestamp(
    value: Any,
    assume_utc: bool = True,
) -> datetime:
    """Convert various timestamp formats to UTC datetime.

    Handles:
    - int/float: Unix timestamp (auto-detects milliseconds vs seconds)
    - str: ISO format or other parseable formats via dateutil
    - datetime: Returns as-is if aware, converts if naive

    Args:
        value: Timestamp as int (ms or s), float, str, or datetime
        assume_utc: If True, treat naive timestamps as UTC (default True)

    Returns:
        Timezone-aware datetime in UTC

    Raises:
        ValueError: If value cannot be parsed as a timestamp

    Example:
        >>> normalize_timestamp(1705084800000)  # milliseconds
        datetime.datetime(2024, 1, 12, 20, 0, tzinfo=datetime.timezone.utc)
        >>> normalize_timestamp("2024-01-12T20:00:00Z")
        datetime.datetime(2024, 1, 12, 20, 0, tzinfo=datetime.timezone.utc)
    """
    if isinstance(value, datetime):
        dt = value
    elif isinstance(value, (int, float)):
        # UniFi uses milliseconds - detect by magnitude
        # Timestamps > 1e12 are definitely milliseconds (after year 2001)
        if value > 1e12:
            value = value / 1000
        dt = datetime.fromtimestamp(value, tz=timezone.utc)
        return dt  # Already UTC, no further conversion needed
    elif isinstance(value, str):
        dt = dateutil_parser.parse(value)
    else:
        raise ValueError(f"Cannot parse timestamp: {value!r} (type: {type(value).__name__})")

    # Handle naive datetimes
    if dt.tzinfo is None:
        if assume_utc:
            dt = dt.replace(tzinfo=timezone.utc)
        else:
            # Treat as local time, then convert to UTC
            dt = dt.astimezone(timezone.utc)
    else:
        # Convert to UTC
        dt = dt.astimezone(timezone.utc)

    return dt
```

Add python-dateutil to requirements if not present (check pyproject.toml or requirements.txt).
  </action>
  <verify>
Run: `python -c "from unifi_scanner.utils import normalize_timestamp; from datetime import timezone; dt = normalize_timestamp(1705084800000); print(dt.tzinfo == timezone.utc, dt.year == 2024)"`
Should print: `True True`
  </verify>
  <done>
normalize_timestamp() handles milliseconds, ISO strings, and datetime objects, always returning UTC-aware datetime.
  </done>
</task>

<task type="auto">
  <name>Task 2: Enhance LogEntry with defensive parsing validators</name>
  <files>src/unifi_scanner/models/log_entry.py</files>
  <action>
Update LogEntry model with Pydantic field validators for defensive parsing:

1. Add imports:
   - `from pydantic import field_validator`
   - `from unifi_scanner.utils.timestamps import normalize_timestamp`

2. Add field_validator for timestamp (mode='before'):
   - Use normalize_timestamp() to convert any input to UTC datetime
   - Catch ValueError and return datetime.now(timezone.utc) as fallback with structlog warning

3. Add field_validator for device_mac (mode='before'):
   - If None or empty, return None
   - Normalize to lowercase, replace '-' with ':'
   - Validate format (6 groups of 2 hex chars) - if invalid, log warning and return original

4. Add field_validator for event_type (mode='before'):
   - If None or empty string, return "UNKNOWN"

5. Update from_unifi_event() classmethod:
   - Use `event.get("time")` as primary timestamp source (milliseconds)
   - Fall back to `event.get("datetime")` if time is missing
   - Extract more device info: also check `event.get("mac")` for device_mac
   - Add subsystem to metadata

6. Add from_syslog() classmethod:
   - Parse syslog format: `"Jan 24 10:30:15 hostname program[pid]: message"`
   - Use regex with named groups for flexible parsing
   - Extract timestamp (add current year since syslog omits year)
   - Set source=LogSource.SYSLOG
   - Store full line in raw_data for debugging
   - Return LogEntry with extracted fields
  </action>
  <verify>
Run: `python -c "from unifi_scanner.models import LogEntry; e = LogEntry.from_unifi_event({'time': 1705084800000, 'key': 'EVT_TEST', 'msg': 'Test'}); print(e.timestamp.year, e.event_type)"`
Should print: `2024 EVT_TEST`
  </verify>
  <done>
LogEntry has defensive validators that handle malformed timestamps, normalize MAC addresses, and default unknown event types. Both from_unifi_event() and from_syslog() factory methods work correctly.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create LogParser for multi-format parsing</name>
  <files>
src/unifi_scanner/logs/__init__.py
src/unifi_scanner/logs/parser.py
tests/test_timestamps.py
tests/test_log_parser.py
  </files>
  <action>
1. Create `src/unifi_scanner/logs/` directory if it doesn't exist.

2. Create `src/unifi_scanner/logs/__init__.py`:
   - Export LogParser

3. Create `src/unifi_scanner/logs/parser.py`:

```python
"""Multi-format log parser for UniFi logs."""

import json
from typing import Any, Dict, List, Optional

import structlog

from unifi_scanner.models import LogEntry

logger = structlog.get_logger(__name__)


class LogParser:
    """Parser for multiple log formats (JSON, syslog).

    Automatically detects format and parses accordingly.
    Handles malformed data gracefully, logging warnings
    and skipping unparseable entries.
    """

    def parse_api_events(self, events: List[Dict[str, Any]]) -> List[LogEntry]:
        """Parse list of events from UniFi API.

        Args:
            events: List of event dictionaries from API response

        Returns:
            List of LogEntry objects (skips unparseable events)
        """
        entries = []
        for i, event in enumerate(events):
            try:
                entry = LogEntry.from_unifi_event(event)
                entries.append(entry)
            except Exception as e:
                logger.warning(
                    "event_parse_failed",
                    index=i,
                    error=str(e),
                    event_key=event.get("key", "unknown"),
                )
        logger.debug("api_events_parsed", total=len(events), successful=len(entries))
        return entries

    def parse_syslog_lines(self, lines: str) -> List[LogEntry]:
        """Parse syslog-formatted log lines.

        Args:
            lines: Multi-line string of syslog entries

        Returns:
            List of LogEntry objects (skips unparseable lines)
        """
        entries = []
        for i, line in enumerate(lines.strip().split('\n')):
            line = line.strip()
            if not line:
                continue
            try:
                entry = LogEntry.from_syslog(line)
                entries.append(entry)
            except Exception as e:
                logger.warning(
                    "syslog_parse_failed",
                    line_num=i + 1,
                    error=str(e),
                    line_preview=line[:100],
                )
        logger.debug("syslog_lines_parsed", total=len(lines.split('\n')), successful=len(entries))
        return entries

    def detect_and_parse(self, data: str) -> List[LogEntry]:
        """Auto-detect format and parse.

        Tries JSON first (API response), falls back to syslog.

        Args:
            data: Raw log data as string

        Returns:
            List of LogEntry objects
        """
        # Try JSON first
        try:
            parsed = json.loads(data)
            if isinstance(parsed, list):
                return self.parse_api_events(parsed)
            elif isinstance(parsed, dict) and "data" in parsed:
                return self.parse_api_events(parsed["data"])
        except json.JSONDecodeError:
            pass

        # Fall back to syslog
        return self.parse_syslog_lines(data)
```

4. Create `tests/test_timestamps.py`:
   - Test millisecond timestamp conversion
   - Test ISO string parsing
   - Test naive datetime handling (assume_utc=True and False)
   - Test invalid input raises ValueError

5. Create `tests/test_log_parser.py`:
   - Test parse_api_events with valid events
   - Test parse_api_events skips invalid events
   - Test parse_syslog_lines with standard format
   - Test detect_and_parse auto-detection
  </action>
  <verify>
Run: `pytest tests/test_timestamps.py tests/test_log_parser.py -v`
All tests should pass.
  </verify>
  <done>
LogParser handles both JSON API events and syslog lines with automatic format detection, graceful error handling, and comprehensive test coverage.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from unifi_scanner.utils import normalize_timestamp; print('timestamp utils ok')"` - imports work
2. `python -c "from unifi_scanner.logs import LogParser; print('parser ok')"` - imports work
3. `pytest tests/test_timestamps.py tests/test_log_parser.py -v` - all tests pass
4. Test defensive parsing: `python -c "from unifi_scanner.models import LogEntry; e = LogEntry.from_unifi_event({'msg': 'No timestamp'}); print(e.timestamp is not None, e.event_type)"`
</verification>

<success_criteria>
- normalize_timestamp() converts milliseconds, strings, and datetimes to UTC
- LogEntry validators handle malformed data without crashing
- MAC addresses normalized to lowercase with colons
- LogParser.parse_api_events() processes lists of event dicts
- LogParser.parse_syslog_lines() handles multi-line syslog data
- detect_and_parse() auto-detects JSON vs syslog format
- Tests cover happy path and edge cases
</success_criteria>

<output>
After completion, create `.planning/phases/02-log-collection-parsing/02-02-SUMMARY.md`
</output>
