---
phase: 01-foundation-api-connection
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/unifi_scanner/models/__init__.py
  - src/unifi_scanner/models/log_entry.py
  - src/unifi_scanner/models/finding.py
  - src/unifi_scanner/models/report.py
  - src/unifi_scanner/models/enums.py
autonomous: true

must_haves:
  truths:
    - "LogEntry model captures all required fields from UniFi logs"
    - "Finding model links back to source LogEntry IDs"
    - "All models serialize to JSON correctly"
    - "Models have extensibility via metadata field"
    - "Severity is constrained to low/medium/severe"
  artifacts:
    - path: "src/unifi_scanner/models/log_entry.py"
      provides: "Normalized log entry model"
      contains: "class LogEntry"
    - path: "src/unifi_scanner/models/finding.py"
      provides: "Analysis finding model"
      contains: "class Finding"
    - path: "src/unifi_scanner/models/report.py"
      provides: "Report container model"
      contains: "class Report"
    - path: "src/unifi_scanner/models/enums.py"
      provides: "Shared enumerations"
      contains: "Severity"
  key_links:
    - from: "src/unifi_scanner/models/finding.py"
      to: "src/unifi_scanner/models/log_entry.py"
      via: "source_log_ids references LogEntry.id"
      pattern: "source_log_ids.*UUID"
    - from: "src/unifi_scanner/models/report.py"
      to: "src/unifi_scanner/models/finding.py"
      via: "findings list contains Finding objects"
      pattern: "findings.*Finding"
---

<objective>
Create core Pydantic data models for LogEntry, Finding, and Report that will be used throughout the application for data flow and serialization.

Purpose: Data models define the contract for how information flows through the system. Well-designed models with proper validation prevent bugs downstream and enable JSON serialization for storage/debugging.

Output: Type-safe Pydantic models with JSON serialization, validation, and extensibility via metadata fields.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation-api-connection/01-CONTEXT.md
@.planning/phases/01-foundation-api-connection/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create enums and LogEntry model</name>
  <files>
    src/unifi_scanner/models/__init__.py
    src/unifi_scanner/models/enums.py
    src/unifi_scanner/models/log_entry.py
  </files>
  <action>
Create src/unifi_scanner/models/enums.py with:
- Severity enum: LOW = "low", MEDIUM = "medium", SEVERE = "severe"
- Category enum: SECURITY = "security", CONNECTIVITY = "connectivity", PERFORMANCE = "performance", SYSTEM = "system"
- LogSource enum: API = "api", SSH = "ssh", SYSLOG = "syslog"
- DeviceType enum: UDM_PRO = "udm_pro", SELF_HOSTED = "self_hosted" (for controller type)

Create src/unifi_scanner/models/log_entry.py with LogEntry class:
- id: UUID (default_factory=uuid4)
- timestamp: datetime (required, when the event occurred)
- source: LogSource (where the log came from)
- device_mac: str | None (MAC of device that generated event, if applicable)
- device_name: str | None (human-readable device name)
- event_type: str (UniFi event type code like "EVT_AP_Connected")
- message: str (human-readable message)
- raw_data: dict[str, Any] (original data for debugging)
- metadata: dict[str, Any] (extensibility field per CONTEXT.md)

Add Pydantic ConfigDict:
- Use json_encoders for datetime (isoformat) and UUID (str)
- Enable from_attributes for ORM compatibility if needed later

Create src/unifi_scanner/models/__init__.py exporting all models and enums
  </action>
  <verify>
    - python -c "from unifi_scanner.models import LogEntry, Severity; print(LogEntry.__fields__.keys())"
    - python -c "from unifi_scanner.models import LogEntry; from datetime import datetime; e = LogEntry(timestamp=datetime.now(), source='api', event_type='test', message='test'); print(e.model_dump_json())"
  </verify>
  <done>LogEntry model exists with all fields, serializes to JSON, has UUID auto-generation</done>
</task>

<task type="auto">
  <name>Task 2: Create Finding and Report models</name>
  <files>
    src/unifi_scanner/models/finding.py
    src/unifi_scanner/models/report.py
    src/unifi_scanner/models/__init__.py
  </files>
  <action>
Create src/unifi_scanner/models/finding.py with Finding class:
- id: UUID (default_factory=uuid4)
- severity: Severity (enum, required)
- category: Category (enum, required)
- title: str (short description like "Failed Login Attempt")
- description: str (detailed plain-English explanation)
- remediation: str | None (step-by-step fix for severe issues)
- source_log_ids: list[UUID] (links to LogEntry.id that triggered this finding)
- occurrence_count: int (default 1, for deduplication)
- first_seen: datetime (when first occurrence was detected)
- last_seen: datetime (when most recent occurrence was detected)
- device_mac: str | None (if finding relates to specific device)
- device_name: str | None (human-readable)
- metadata: dict[str, Any] (extensibility)

Add validator: last_seen >= first_seen

Create src/unifi_scanner/models/report.py with Report class:
- id: UUID (default_factory=uuid4)
- generated_at: datetime (default_factory=datetime.utcnow)
- period_start: datetime (analysis window start)
- period_end: datetime (analysis window end)
- site_name: str (UniFi site name)
- controller_type: DeviceType (what type of controller)
- findings: list[Finding] (all findings, can be empty)
- log_entry_count: int (how many logs were analyzed)
- metadata: dict[str, Any] (extensibility)

Add computed properties:
- severe_count: int (count of findings with severity=SEVERE)
- medium_count: int
- low_count: int

Update src/unifi_scanner/models/__init__.py to export Finding, Report
  </action>
  <verify>
    - python -c "from unifi_scanner.models import Finding, Severity, Category; from datetime import datetime; f = Finding(severity=Severity.SEVERE, category=Category.SECURITY, title='Test', description='Test desc', first_seen=datetime.now(), last_seen=datetime.now()); print(f.model_dump_json())"
    - python -c "from unifi_scanner.models import Report, DeviceType; from datetime import datetime; r = Report(period_start=datetime.now(), period_end=datetime.now(), site_name='default', controller_type=DeviceType.UDM_PRO); print(r.severe_count)"
  </verify>
  <done>Finding and Report models exist, Finding links to LogEntry via source_log_ids, Report has severity count properties</done>
</task>

<task type="auto">
  <name>Task 3: Add model utility methods and tests</name>
  <files>
    src/unifi_scanner/models/log_entry.py
    src/unifi_scanner/models/finding.py
    tests/test_models.py
  </files>
  <action>
Add utility methods to LogEntry:
- @classmethod from_unifi_event(cls, event_data: dict) -> LogEntry: Factory for creating from raw UniFi API response (stub implementation that extracts common fields, will be enhanced in Phase 2)

Add utility methods to Finding:
- add_occurrence(self, log_id: UUID, timestamp: datetime): Increment count, update last_seen, append log_id
- @property is_actionable(self) -> bool: True if severity is SEVERE and remediation exists

Create tests/test_models.py with basic tests:
- Test LogEntry creation with all fields
- Test LogEntry JSON serialization roundtrip
- Test Finding severity constraint (only low/medium/severe)
- Test Finding.add_occurrence updates correctly
- Test Report computed properties (severe_count, etc.)
- Test all models have metadata field defaulting to empty dict

Use pytest for test framework. Create minimal conftest.py if needed.

Note: Do NOT add pytest to pyproject.toml dependencies yet - it's a dev dependency. Just ensure tests work with `pip install pytest && pytest tests/`
  </action>
  <verify>
    - pip install pytest
    - pytest tests/test_models.py -v
    - All tests pass
  </verify>
  <done>Models have utility methods, tests verify core functionality, JSON roundtrip works</done>
</task>

</tasks>

<verification>
Overall plan verification:
1. All model classes import without error
2. Models serialize to JSON and deserialize correctly
3. Finding.source_log_ids correctly links to LogEntry UUIDs
4. Report.findings contains Finding objects
5. Computed properties (severe_count, etc.) work correctly
6. All models have metadata field for extensibility
7. Tests pass with pytest
</verification>

<success_criteria>
- LogEntry captures: id, timestamp, source, device_mac, event_type, message, raw_data, metadata
- Finding captures: id, severity, category, title, description, remediation, source_log_ids, occurrence_count, first_seen, last_seen, metadata
- Report captures: id, generated_at, period_start, period_end, site_name, controller_type, findings, log_entry_count, metadata
- All models JSON serializable with datetime and UUID handling
- Severity constrained to enum values (low/medium/severe)
- Tests verify core model behavior
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-api-connection/01-02-SUMMARY.md`
</output>
