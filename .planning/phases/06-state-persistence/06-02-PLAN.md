---
phase: 06-state-persistence
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - src/unifi_scanner/logs/collector.py
  - src/unifi_scanner/logs/api_collector.py
  - src/unifi_scanner/__main__.py
  - tests/test_log_collector_since.py
autonomous: true

must_haves:
  truths:
    - "Service reads last run timestamp before collecting logs"
    - "Service only processes events newer than last successful run"
    - "First run with no state processes events from initial_lookback_hours"
    - "State is only updated after successful delivery"
    - "Empty report (no new events) sends confirmation message"
  artifacts:
    - path: "src/unifi_scanner/logs/collector.py"
      provides: "LogCollector with since_timestamp parameter"
      contains: "since_timestamp"
    - path: "src/unifi_scanner/logs/api_collector.py"
      provides: "APILogCollector with timestamp filtering"
      contains: "since_timestamp"
    - path: "src/unifi_scanner/__main__.py"
      provides: "State lifecycle integration in run_report_job"
      contains: "StateManager"
  key_links:
    - from: "src/unifi_scanner/__main__.py"
      to: "src/unifi_scanner/state/manager.py"
      via: "StateManager.read_last_run() and write_last_run()"
      pattern: "state_manager\\.(read|write)_last_run"
    - from: "src/unifi_scanner/logs/collector.py"
      to: "src/unifi_scanner/logs/api_collector.py"
      via: "since_timestamp parameter forwarding"
      pattern: "since_timestamp.*APILogCollector"
---

<objective>
Integrate state persistence into the log collection and report delivery pipeline.

Purpose: This completes the state persistence feature by connecting StateManager to LogCollector and run_report_job, ensuring the service only processes new events and updates state only after successful delivery.

Output: Modified log collection with timestamp filtering, integrated state lifecycle in the main job, and empty report handling.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/SUMMARY.md
@.planning/phases/06-state-persistence/06-01-SUMMARY.md

# Implementation references
@src/unifi_scanner/logs/collector.py
@src/unifi_scanner/logs/api_collector.py
@src/unifi_scanner/__main__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add since_timestamp filtering to log collectors</name>
  <files>
    src/unifi_scanner/logs/api_collector.py
    src/unifi_scanner/logs/collector.py
  </files>
  <action>
**APILogCollector changes** (api_collector.py):

1. Add `since_timestamp: Optional[datetime] = None` parameter to `__init__`
2. In `collect()`, after parsing events/alarms, filter by timestamp:
```python
# After parsing, filter by since_timestamp if provided
if self.since_timestamp:
    entries = [
        e for e in entries
        if e.timestamp > self.since_timestamp
    ]
    logger.debug(
        "api_entries_filtered",
        before_filter=len(unfiltered),
        after_filter=len(entries),
        since=self.since_timestamp.isoformat(),
    )
```

Note: Filtering is client-side because UniFi API doesn't support timestamp filtering on events endpoint. The API has history_hours but not a start timestamp parameter.

**LogCollector changes** (collector.py):

1. Add `since_timestamp: Optional[datetime] = None` parameter to `collect()` method
2. Pass since_timestamp to APILogCollector:
```python
api_collector = APILogCollector(
    client=self.client,
    site=self.site,
    history_hours=history_hours,
    since_timestamp=since_timestamp,  # New parameter
)
```
3. For SSH fallback, also filter by since_timestamp if provided (defensive, same pattern)

**Clock skew tolerance** (STATE-07):
Add 5-minute tolerance by subtracting timedelta from comparison:
```python
# In APILogCollector, adjust for clock skew (5 min grace period)
effective_cutoff = self.since_timestamp - timedelta(minutes=5)
entries = [e for e in entries if e.timestamp > effective_cutoff]
```

Import `timedelta` from datetime at top of file.
  </action>
  <verify>
    - `python -c "from unifi_scanner.logs.collector import LogCollector; import inspect; sig = inspect.signature(LogCollector.collect); assert 'since_timestamp' in sig.parameters"` passes
    - Unit tests for timestamp filtering pass
  </verify>
  <done>
    - LogCollector.collect() accepts since_timestamp parameter
    - APILogCollector filters events by timestamp (client-side)
    - 5-minute clock skew tolerance applied
    - SSH fallback also respects since_timestamp
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate state lifecycle into run_report_job</name>
  <files>src/unifi_scanner/__main__.py</files>
  <action>
Modify `run_report_job()` to implement the checkpoint-after-delivery pattern:

**At top of function**, after getting config:
```python
from unifi_scanner.state import StateManager

# Initialize state manager (state file in reports directory)
state_dir = config.file_output_dir or "./reports"
state_manager = StateManager(state_dir=state_dir)

# Read last successful run timestamp
last_run = state_manager.read_last_run()
if last_run:
    log.info("state_loaded", last_run=last_run.isoformat())
    since_timestamp = last_run
else:
    # First run - use initial lookback
    since_timestamp = datetime.now(timezone.utc) - timedelta(hours=config.initial_lookback_hours)
    log.info("first_run", lookback_hours=config.initial_lookback_hours)
```

**In log collection** (pass since_timestamp to collector):
```python
log_entries = collector.collect(since_timestamp=since_timestamp)
```

**After successful delivery** (only if manager.deliver() returns True):
```python
if success:
    # Update state only after successful delivery
    state_manager.write_last_run(
        timestamp=report.generated_at,
        report_count=len(findings),
    )
    log.info("state_updated", timestamp=report.generated_at.isoformat())
```

**Report period calculation**:
Update the Report construction to use since_timestamp:
```python
report = Report(
    period_start=since_timestamp,  # Use actual cutoff, not hardcoded 24h
    period_end=now,
    ...
)
```

Import StateManager at top with other imports.
  </action>
  <verify>
    - `python -c "from unifi_scanner.__main__ import run_report_job"` imports successfully
    - grep confirms StateManager usage: `grep -n "StateManager" src/unifi_scanner/__main__.py`
  </verify>
  <done>
    - run_report_job reads state before collection
    - First run uses initial_lookback_hours
    - Subsequent runs use last_successful_run timestamp
    - State updated only after successful delivery
    - Report period_start reflects actual timestamp cutoff
  </done>
</task>

<task type="auto">
  <name>Task 3: Handle empty reports (no new events)</name>
  <files>src/unifi_scanner/__main__.py</files>
  <action>
When log_entries is empty after filtering (no new events since last run), deliver a confirmation message instead of skipping.

**After log collection**, check for empty results:
```python
log_entries = collector.collect(since_timestamp=since_timestamp)
log.info("logs_collected", count=len(log_entries))

# Handle empty result (no new events)
if not log_entries:
    log.info("no_new_events", since=since_timestamp.isoformat())

    # Generate empty report with confirmation message
    now = datetime.now(timezone.utc)
    report = Report(
        period_start=since_timestamp,
        period_end=now,
        site_name=site,
        controller_type=client.device_type or DeviceType.UNKNOWN,
        findings=[],  # Empty findings
        log_entry_count=0,
    )

    # Generate report content
    generator = ReportGenerator(display_timezone=config.schedule_timezone)
    html_content = generator.generate_html(report)
    text_content = generator.generate_text(report)

    # Deliver (this will show "No new security events since last report")
    # ... delivery code ...
```

The existing report templates already handle empty findings lists and show appropriate messaging. Verify the templates display "No security events" or similar when findings is empty.

**Important**: Still update state after successful empty report delivery. The user should not re-receive the same "no events" report.

Note: The CONF-02 requirement "Empty report sends confirmation message" is handled by the existing templates - when findings=[], the report shows "No security events detected" in summary section.
  </action>
  <verify>
    - Run with mock data returning empty log_entries, verify report is still generated and delivered
    - Check report content includes "no events" messaging
  </verify>
  <done>
    - Empty log results do not crash or skip delivery
    - Empty report is generated with proper messaging
    - State is updated after successful empty report delivery
    - Next run continues from correct timestamp
  </done>
</task>

</tasks>

<verification>
All verification commands should pass:

```bash
# Check since_timestamp parameter exists
python -c "from unifi_scanner.logs.collector import LogCollector; import inspect; print('since_timestamp' in str(inspect.signature(LogCollector.collect)))"

# Check StateManager integration
grep -n "StateManager" src/unifi_scanner/__main__.py

# Check state read/write in job
grep -n "read_last_run\|write_last_run" src/unifi_scanner/__main__.py

# Run tests
pytest tests/test_log_collector_since.py -v
```
</verification>

<success_criteria>
- LogCollector.collect() accepts and uses since_timestamp parameter
- run_report_job() reads state before collection
- run_report_job() writes state only after successful delivery
- First run uses initial_lookback_hours configuration
- Empty reports are handled gracefully with confirmation message
- State is updated even for empty reports
</success_criteria>

<output>
After completion, create `.planning/phases/06-state-persistence/06-02-SUMMARY.md`
</output>
