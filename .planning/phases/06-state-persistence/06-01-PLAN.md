---
phase: 06-state-persistence
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/unifi_scanner/state/__init__.py
  - src/unifi_scanner/state/manager.py
  - src/unifi_scanner/config/settings.py
  - tests/test_state_manager.py
autonomous: true

must_haves:
  truths:
    - "StateManager can read last successful run timestamp from state file"
    - "StateManager can write state atomically (no partial writes on crash)"
    - "Missing state file returns None (first run scenario)"
    - "Corrupted state file returns None with warning log"
    - "Initial lookback hours is configurable via UNIFI_INITIAL_LOOKBACK_HOURS"
  artifacts:
    - path: "src/unifi_scanner/state/manager.py"
      provides: "StateManager class with read/write/atomic operations"
      exports: ["StateManager", "RunState"]
    - path: "src/unifi_scanner/state/__init__.py"
      provides: "Package exports"
      exports: ["StateManager", "RunState"]
    - path: "src/unifi_scanner/config/settings.py"
      provides: "initial_lookback_hours configuration field"
      contains: "initial_lookback_hours"
  key_links:
    - from: "src/unifi_scanner/state/manager.py"
      to: "tempfile + shutil.move"
      via: "atomic write pattern"
      pattern: "tempfile\\.mkstemp.*shutil\\.move"
---

<objective>
Create the StateManager module for tracking last successful report timestamp with atomic writes.

Purpose: This foundation enables preventing duplicate event reporting by persisting the last successful run timestamp. The StateManager uses the same atomic write pattern as FileDelivery to ensure crash-safe state persistence.

Output: StateManager class with read_last_run() and write_last_run() methods, plus configuration for initial lookback hours.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/SUMMARY.md

# Key implementation references
@src/unifi_scanner/delivery/file.py (lines 61-80 for atomic write pattern)
@src/unifi_scanner/config/settings.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create StateManager module with atomic write pattern</name>
  <files>
    src/unifi_scanner/state/__init__.py
    src/unifi_scanner/state/manager.py
  </files>
  <action>
Create the state management module by copying the atomic write pattern from FileDelivery._atomic_write().

**RunState dataclass** (in manager.py):
```python
@dataclass
class RunState:
    last_successful_run: datetime  # UTC timezone-aware
    last_report_count: int = 0
    schema_version: str = "1.0"
```

**StateManager class**:
- `__init__(self, state_dir: str)`: Store state_dir path, state file is `.last_run.json` in that directory
- `read_last_run(self) -> Optional[datetime]`:
  - Return None if file doesn't exist (first run)
  - Return None with warning log if file is corrupted/unparseable
  - Return datetime (UTC) if valid state exists
  - Use `json.loads()` to parse, `datetime.fromisoformat()` to parse timestamp
  - Validate timestamp is timezone-aware UTC
- `write_last_run(self, timestamp: datetime, report_count: int = 0) -> None`:
  - Create state directory if doesn't exist
  - Use atomic write pattern: tempfile.mkstemp() in same dir, write, then shutil.move()
  - Store ISO 8601 UTC timestamp string
  - Store schema_version for future migrations

**State file format** (.last_run.json):
```json
{
  "last_successful_run": "2026-01-24T14:30:00+00:00",
  "last_report_count": 3,
  "schema_version": "1.0"
}
```

**Error handling**:
- FileNotFoundError -> return None (expected first run)
- json.JSONDecodeError -> log warning "state_file_corrupted", return None
- ValueError (bad timestamp) -> log warning "state_timestamp_invalid", return None
- PermissionError on write -> log error, raise (configuration error)

Use structlog for logging consistent with rest of codebase.
  </action>
  <verify>
    - `python -c "from unifi_scanner.state import StateManager, RunState"` imports successfully
    - Unit tests pass for StateManager
  </verify>
  <done>
    - StateManager.read_last_run() returns None for missing file
    - StateManager.read_last_run() returns datetime for valid state
    - StateManager.read_last_run() returns None with warning for corrupted file
    - StateManager.write_last_run() creates valid JSON state file
    - Atomic write pattern prevents partial writes
  </done>
</task>

<task type="auto">
  <name>Task 2: Add initial_lookback_hours configuration</name>
  <files>src/unifi_scanner/config/settings.py</files>
  <action>
Add new configuration field to UnifiSettings class:

```python
# State persistence settings (add after schedule settings)
initial_lookback_hours: int = Field(
    default=24,
    description="Hours of history to process on first run (when no state file exists)",
    gt=0,
    le=720,  # Max 30 days to match API limits
)
```

This maps to environment variable `UNIFI_INITIAL_LOOKBACK_HOURS`.

No validators needed - Pydantic handles int parsing and range validation via Field constraints.
  </action>
  <verify>
    - `python -c "from unifi_scanner.config import UnifiSettings; s = UnifiSettings(host='test', username='test'); print(s.initial_lookback_hours)"` prints 24
    - `UNIFI_INITIAL_LOOKBACK_HOURS=48 python -c "from unifi_scanner.config import UnifiSettings; s = UnifiSettings(host='test', username='test'); print(s.initial_lookback_hours)"` prints 48
  </verify>
  <done>
    - initial_lookback_hours field exists with default 24
    - Environment variable UNIFI_INITIAL_LOOKBACK_HOURS overrides default
    - Range validation enforces 1-720 hours
  </done>
</task>

<task type="auto">
  <name>Task 3: Write comprehensive StateManager tests</name>
  <files>tests/test_state_manager.py</files>
  <action>
Create test file with pytest following existing test patterns in the codebase.

**Test cases**:

1. `test_read_missing_file_returns_none`: New state dir with no file returns None
2. `test_read_valid_state_returns_datetime`: Write valid JSON, read returns correct UTC datetime
3. `test_read_corrupted_json_returns_none`: Write invalid JSON, read returns None (check log warning)
4. `test_read_invalid_timestamp_returns_none`: Write JSON with bad timestamp format, returns None
5. `test_read_missing_required_field_returns_none`: Write JSON missing last_successful_run, returns None
6. `test_write_creates_directory`: Write to non-existent directory, directory created
7. `test_write_creates_valid_json`: Write state, read back JSON matches expected format
8. `test_write_is_atomic`:
   - Mock shutil.move to fail
   - Verify temp file is cleaned up
   - Verify original state file unchanged if existed
9. `test_write_overwrites_existing`: Write twice, second value persists
10. `test_roundtrip_preserves_timezone`: Write UTC datetime, read back is UTC

Use `tmp_path` fixture for isolated test directories.
Use `caplog` fixture to verify warning logs on corruption.

Follow existing test patterns - see tests/test_delivery_file.py for reference.
  </action>
  <verify>
    - `pytest tests/test_state_manager.py -v` passes all tests
  </verify>
  <done>
    - All 10+ test cases pass
    - Edge cases for corruption and missing files covered
    - Atomic write behavior verified
  </done>
</task>

</tasks>

<verification>
All verification commands should pass:

```bash
# Module imports
python -c "from unifi_scanner.state import StateManager, RunState"

# Config field
python -c "from unifi_scanner.config import UnifiSettings; s = UnifiSettings(host='test', username='test'); assert s.initial_lookback_hours == 24"

# Tests
pytest tests/test_state_manager.py -v
```
</verification>

<success_criteria>
- StateManager module exists and is importable
- read_last_run() handles all error cases gracefully (missing, corrupted, invalid)
- write_last_run() uses atomic write pattern (temp file + rename)
- initial_lookback_hours config field works with env var override
- All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-state-persistence/06-01-SUMMARY.md`
</output>
